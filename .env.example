# ╔══════════════════════════════════════════════════════════════════════════════╗
# ║                     threelane-memory · Configuration                       ║
# ╚══════════════════════════════════════════════════════════════════════════════╝
#
# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ QUICK START                                                                │
# │                                                                            │
# │  1. Copy this file:  cp .env.example .env                                 │
# │  2. Choose a provider below (ollama = local, openai = cloud)              │
# │  3. Fill in your Neo4j credentials                                        │
# │  4. Run: threelane-memory config   ← verify everything is correct         │
# │                                                                            │
# │ SWITCHING PROVIDERS                                                        │
# │                                                                            │
# │  Ollama → OpenAI:                                                          │
# │   1. Set LLM_PROVIDER=openai                                              │
# │   2. Uncomment and fill OPENAI_API_KEY                                    │
# │   3. Run: threelane-memory config        ← check for dimension warnings   │
# │   4. Run: threelane-memory reindex ...   ← re-embed with new model        │
# │                                                                            │
# │  OpenAI → Ollama:                                                          │
# │   1. Install Ollama: brew install ollama && ollama serve                   │
# │   2. Pull models: ollama pull llama3.2:3b && ollama pull nomic-embed-text  │
# │   3. Set LLM_PROVIDER=ollama                                              │
# │   4. Run: threelane-memory config        ← check for dimension warnings   │
# │   5. Run: threelane-memory reindex ...   ← re-embed with new model        │
# │                                                                            │
# │ NOTE: Different embedding models produce different vector dimensions.      │
# │ The CLI will warn you if your Neo4j index dimension doesn't match.         │
# │ Run `threelane-memory config` after any provider change to verify.         │
# └─────────────────────────────────────────────────────────────────────────────┘

# ── LLM Provider ──────────────────────────────────────────────────────────────
# Supported values: "ollama" (local, free) | "openai" (cloud, API key required)
LLM_PROVIDER=ollama

# ── Ollama (local) ───────────────────────────────────────────────────────────
# Used when LLM_PROVIDER=ollama
# Install: brew install ollama && ollama serve
# Models:  ollama pull llama3.2:3b && ollama pull nomic-embed-text
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3.2:3b                # Chat model (alternatives: mistral, gemma2)
OLLAMA_EMBED_MODEL=nomic-embed-text          # Embedding model (768-dim)

# ── OpenAI (cloud) ───────────────────────────────────────────────────────────
# Used when LLM_PROVIDER=openai
# Get your key at https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-api-key
# OPENAI_CHAT_MODEL=gpt-4o                  # Chat model
# OPENAI_EMBED_MODEL=text-embedding-ada-002  # Embedding model (1536-dim)

# ── Embedding Dimension (auto-detected) ──────────────────────────────────────
# Normally auto-set from the model name. Override only for custom models.
# Known dimensions:  nomic-embed-text=768  |  text-embedding-ada-002=1536
# EMBEDDING_DIM=768

# ── Neo4j ─────────────────────────────────────────────────────────────────────
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-password

# ── Retrieval Scoring Weights (optional) ──────────────────────────────────────
# WEIGHT_SIMILARITY=0.65
# WEIGHT_IMPORTANCE=0.30
# WEIGHT_RECENCY=0.05
# RECENCY_HALF_LIFE_DAYS=365
# IMPORTANCE_FLOOR=0.75

# ── Dynamic Candidate Pool (optional) ────────────────────────────────────────
# VECTOR_CANDIDATES_MIN=50
# VECTOR_CANDIDATES_MAX=500
# VECTOR_CANDIDATES_RATIO=0.02

# ── Consolidation (optional) ─────────────────────────────────────────────────
# CONSOLIDATION_AGE_DAYS=90
# CONSOLIDATION_BATCH_SIZE=50
# CONSOLIDATION_IMPORTANCE_CAP=0.3

# ── Backup (optional) ────────────────────────────────────────────────────────
# BACKUP_DIR=./backups
